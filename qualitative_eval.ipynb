{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from re import sub \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pycocotools.coco import COCO\n",
    "# import matplotlib.pyplot as plt\n",
    "# import skimage.io as io\n",
    "\n",
    "from agent import Agent\n",
    "from environment import Environment\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 500\n",
    "SPLIT = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_LSTM = 'RETRAIN-0512-2307-E9'\n",
    "SCST = 'RL-0516-1547-E9'\n",
    "CONTEXT_1 = 'RL-0517-0417-E9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED ACTOR WITH BASE_LSTM WEIGHTS:  RETRAIN-0512-2307-E9\n",
      "loading annotations into memory...\n",
      "Done (t=0.26s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "env = Environment()\n",
    "agent = Agent(env=env)\n",
    "agent.actor.load_state_dict(torch.load(\n",
    "    MODEL_DIR.format(BASE_LSTM), map_location=None if USE_CUDA else 'cpu'\n",
    ")['model_state_dict'])\n",
    "print('LOADED ACTOR WITH BASE_LSTM WEIGHTS: ', BASE_LSTM)\n",
    "coco = COCO(CAPTIONS_DIR.format('val'))\n",
    "\n",
    "with open(KARPATHY_SPLIT_DIR.format(SPLIT)) as f:\n",
    "    img_ids = f.read().split('\\n')[:-1]\n",
    "img_ids = [int(x.split()[-1]) for x in img_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids_ = np.random.choice(img_ids, size=NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "caption_ids = coco.getAnnIds(img_ids_)\n",
    "captions = np.array([' '.join([sub(r'[^\\w ]', '', caption['caption'].lower()).strip(), '<EOS>'])\n",
    "                    for caption in coco.loadAnns(caption_ids)]).reshape(NUM_SAMPLES, -1)\n",
    "\n",
    "# UGH\n",
    "captions = list(map(list, captions))\n",
    "ground_truth = dict(zip(img_ids_, captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_features = torch.Tensor(\n",
    "    [np.load(FEATURES_DIR.format(img_id))\n",
    "     for img_id in img_ids_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0530917078059252\n"
     ]
    }
   ],
   "source": [
    "predictions = agent.predict_captions(img_features, mode='greedy', constrain=True)\n",
    "predictions_ = dict(zip(img_ids_, predictions))\n",
    "mean, scores = env.cider.compute_score(ground_truth, predictions_)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_idxs = np.argsort(scores)[-5:]\n",
    "# worst_idxs = np.argsort(scores)[:5]\n",
    "\n",
    "# print('Image IDs where we got the highest scores: ', img_ids_[top_idxs])\n",
    "# print('with scores: ', scores[top_idxs])\n",
    "# print('Image IDs where we got the worst scores: ', img_ids_[worst_idxs])\n",
    "# print('with scores: ', scores[worst_idxs])\n",
    "\n",
    "# GET 5 RANDOM INDECES\n",
    "idxs = np.random.choice(len(scores), 10)\n",
    "top_idxs = idxs[:5]\n",
    "worst_idxs = idxs[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # insert code here to show the pictures...\n",
    "# img = coco.loadImgs(imgId)[0]\n",
    "# I = io.imread('%s/images/%s/%s'%(dataDir,dataType,img['file_name']))\n",
    "# plt.imshow(I)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captions from top scoring:\n",
      "[['a group of motorcycles parked on the side of a street <EOS>']\n",
      " ['a traffic light on the side of a street <EOS>']\n",
      " ['a group of people walking down a street with a bus <EOS>']\n",
      " ['a man holding a tennis ball on a tennis court <EOS>']\n",
      " ['a train is sitting at a train station <EOS>']]\n",
      "Captions from worst scoring:\n",
      "[['a herd of horses are walking in the water <EOS>']\n",
      " ['a boat is sitting in the water <EOS>']\n",
      " ['a man is flying a kite on the beach <EOS>']\n",
      " ['a bathroom with a toilet and a sink <EOS>']\n",
      " ['a group of people flying kites in a field <EOS>']]\n"
     ]
    }
   ],
   "source": [
    "print('Captions from top scoring:')\n",
    "print(np.array(predictions)[top_idxs])\n",
    "\n",
    "print('Captions from worst scoring:')\n",
    "print(np.array(predictions)[worst_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth captions for top scoring: \n",
      "[['one bicycle is parked next to many motorcycles <EOS>'\n",
      "  'a row of motorcycles next to a bicycle <EOS>'\n",
      "  'a group of bikes and motorcycles parked on a city street <EOS>'\n",
      "  'bicycles and scooters lined up along the sidewalk in a quaint town <EOS>'\n",
      "  'bicycles lined up on the side of the road <EOS>']\n",
      " ['a traffic signal sitting next to a street at night <EOS>'\n",
      "  'traffic light at night appearing very confusing <EOS>'\n",
      "  'the electronic stop sign glows brightly at night time <EOS>'\n",
      "  'a variety of traffic lights and road signs <EOS>'\n",
      "  'there is a street light with two green arrows in different directions <EOS>']\n",
      " ['an ambulance and police cars are stopped at the scene of an accident <EOS>'\n",
      "  'an ambulance and police are on the side of the road <EOS>'\n",
      "  'an ambulance police cars and firetruck attending to some kind of road emergency <EOS>'\n",
      "  'an ambulance and cop cars at an accident in a street <EOS>'\n",
      "  'an accident on a road with an ambulance and police on the scene <EOS>']\n",
      " ['a man holding a tennis racquet and a tennis ball <EOS>'\n",
      "  'man in black shorts and red shirt playing tennis <EOS>'\n",
      "  'red shirted tennis player preparing to serve ball <EOS>'\n",
      "  'a man with a tennis racket and ball leaning forward <EOS>'\n",
      "  'a man holding a tennis ball and a tennis racket <EOS>']\n",
      " ['a picture of two buildings and a street in blackandwhite <EOS>'\n",
      "  'a train is stopped at an empty train station <EOS>'\n",
      "  'a train is at an empty train station <EOS>'\n",
      "  'a black and white photo of a train station <EOS>'\n",
      "  'a train stopped at an empty train station <EOS>']]\n"
     ]
    }
   ],
   "source": [
    "print('Ground truth captions for top scoring: ')\n",
    "print(np.array(captions)[top_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth captions for worst scoring: \n",
      "[['a bunch of horses that are standing in the water <EOS>'\n",
      "  'two men riding horses and many horses water dirt and trees <EOS>'\n",
      "  'two men on horseback herd some horses across a stream <EOS>'\n",
      "  'a herd of horses runs through a stream <EOS>'\n",
      "  'cowboys herding horses across a small stream in a valley <EOS>']\n",
      " ['a large metal fork sticking out of a lake next to a boat <EOS>'\n",
      "  'an image a large fork perched in the water <EOS>'\n",
      "  'a seemingly very large fork stuck in the water  with a ship behind it <EOS>'\n",
      "  'a large fork sculpture stands in the water as a large boat passes <EOS>'\n",
      "  'a large fork on the water where a boat is in the background <EOS>']\n",
      " ['a person flying a kite on a beach at dusk <EOS>'\n",
      "  'two people on the beach and one is flying a kite <EOS>'\n",
      "  'a couple of people on a beach flying a kite <EOS>'\n",
      "  'people flying a yellow kite on at sunrise on a beach <EOS>'\n",
      "  'a kite flying in the air over a sand castle <EOS>']\n",
      " ['a bathroom scene with focus on the toilet and the sink <EOS>'\n",
      "  'a bathroom has a white wicker cabinet on the wall <EOS>'\n",
      "  'a cabinet in a bathroom has been improperly painted <EOS>'\n",
      "  'photo taken through open door into a bathroom <EOS>'\n",
      "  'a bathroom with a sink and a toilet <EOS>']\n",
      " ['several people in a green field flying kites <EOS>'\n",
      "  'a group of people standing on top of a lush green field <EOS>'\n",
      "  'a group of people are flying kites in the sky <EOS>'\n",
      "  'many people are standing in a field underneath flying kites <EOS>'\n",
      "  'a large group of people flying and looking at kites <EOS>']]\n"
     ]
    }
   ],
   "source": [
    "print('Ground truth captions for worst scoring: ')\n",
    "print(np.array(captions)[worst_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate SCST on the same images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED ACTOR WITH SCST WEIGHTS:  RL-0516-1547-E9\n"
     ]
    }
   ],
   "source": [
    "agent_scst = Agent(env=env)\n",
    "agent_scst.actor.load_state_dict(torch.load(\n",
    "    MODEL_DIR.format(SCST), map_location=None if USE_CUDA else 'cpu'\n",
    ")['model_state_dict'])\n",
    "print('LOADED ACTOR WITH SCST WEIGHTS: ', SCST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1298931554750955\n"
     ]
    }
   ],
   "source": [
    "predictions = agent_scst.predict_captions(img_features, mode='greedy', constrain=True)\n",
    "predictions_ = dict(zip(img_ids_, predictions))\n",
    "mean, scores = env.cider.compute_score(ground_truth, predictions_)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a group of motorcycles parked on the side of a street <EOS>']\n",
      " ['a traffic light on the side of a street <EOS>']\n",
      " ['a group of people walking down a street with a bus <EOS>']\n",
      " ['a man holding a tennis ball on a tennis court <EOS>']\n",
      " ['a train is sitting at a train station <EOS>']]\n",
      "[['a herd of horses are walking in the water <EOS>']\n",
      " ['a boat is sitting in the water <EOS>']\n",
      " ['a man is flying a kite on the beach <EOS>']\n",
      " ['a bathroom with a toilet and a sink <EOS>']\n",
      " ['a group of people flying kites in a field <EOS>']]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(predictions)[top_idxs])\n",
    "print(np.array(predictions)[worst_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice some improvements on the sentences!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate CIDEr + Context Reward on the same images\n",
    "### ($\\beta = 0.5$)\n",
    "\n",
    "Version 1: 180 - mean_pred_dist\n",
    "\n",
    "Up to Epoch=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_context = Agent(env=env)\n",
    "agent_context.actor.load_state_dict(torch.load(\n",
    "    MODEL_DIR.format('RL-0517-0417-E4'), map_location=None if USE_CUDA else 'cpu'\n",
    ")['model_state_dict'])\n",
    "# print('LOADED ACTOR WITH SCST WEIGHTS: ', SCST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = agent_context.predict_captions(img_features, mode='greedy', constrain=True)\n",
    "predictions_ = dict(zip(img_ids_, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, scores = env.cider.compute_score(ground_truth, predictions_)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(np.array(predictions)[top_idxs])\n",
    "print(np.array(predictions)[worst_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate CIDEr + Context Reward on the same images\n",
    "### ($\\beta = 0.5$)\n",
    "\n",
    "Version 1: 180 - mean_pred_dist\n",
    "\n",
    "Up to Epoch=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_context = Agent(env=env)\n",
    "agent_context.actor.load_state_dict(torch.load(\n",
    "    MODEL_DIR.format('RL-0517-0417-E9'), map_location=None if USE_CUDA else 'cpu'\n",
    ")['model_state_dict'])\n",
    "# print('LOADED ACTOR WITH SCST WEIGHTS: ', SCST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.067835275130549\n"
     ]
    }
   ],
   "source": [
    "predictions = agent_context.predict_captions(img_features, mode='greedy', constrain=True)\n",
    "predictions_ = dict(zip(img_ids_, predictions))\n",
    "mean, scores = env.cider.compute_score(ground_truth, predictions_)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a man is doing a trick on a skateboard <EOS>']\n",
      " ['a motorcycle is parked on the side of a road <EOS>']\n",
      " ['a woman is sitting in the rain with an umbrella <EOS>']\n",
      " ['a pair of scissors sitting on top of a table <EOS>']\n",
      " ['a clock tower on the top of a building <EOS>']]\n",
      "[['two zebras are standing in a field <EOS>']\n",
      " ['a living room with a couch and a table <EOS>']\n",
      " ['a train is sitting at a train station <EOS>']\n",
      " ['a bathroom with a toilet and a sink <EOS>']\n",
      " ['a man is riding a wave on a surfboard <EOS>']]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(predictions)[top_idxs])\n",
    "print(np.array(predictions)[worst_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate CIDEr + Context Reward on the same images\n",
    "### ($\\beta = 0.1$, LR=5e-4)\n",
    "\n",
    "Version 2: `1 - [(gt - pred) / gt]`\n",
    "\n",
    "Up to Epoch=5, Greedy context up to 0.84~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_context = Agent(env=env)\n",
    "agent_context.actor.load_state_dict(torch.load(\n",
    "    MODEL_DIR.format('RL-0522-0942-E4'), map_location=None if USE_CUDA else 'cpu'\n",
    ")['model_state_dict'])\n",
    "# print('LOADED ACTOR WITH SCST WEIGHTS: ', SCST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = agent_context.predict_captions(img_features, mode='greedy', constrain=True)\n",
    "predictions_ = dict(zip(img_ids_, predictions))\n",
    "mean, scores = env.cider.compute_score(ground_truth, predictions_)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.array(predictions)[top_idxs])\n",
    "print(np.array(predictions)[worst_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate CIDEr + Context Reward on the same images\n",
    "### ($\\beta = 0.1$, LR=1e-4)\n",
    "\n",
    "Version 2: `1 - [(gt - pred) / gt]`\n",
    "\n",
    "Up to Epoch=5, Greedy context up to 0.8388"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_context = Agent(env=env)\n",
    "agent_context.actor.load_state_dict(torch.load(\n",
    "    MODEL_DIR.format('RL-0522-1313-E4'), map_location=None if USE_CUDA else 'cpu'\n",
    ")['model_state_dict'])\n",
    "# print('LOADED ACTOR WITH SCST WEIGHTS: ', SCST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9639909200550679\n"
     ]
    }
   ],
   "source": [
    "predictions = agent_context.predict_captions(img_features, mode='greedy', constrain=True)\n",
    "predictions_ = dict(zip(img_ids_, predictions))\n",
    "mean, scores = env.cider.compute_score(ground_truth, predictions_)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a man riding a skateboard on a ramp <EOS>']\n",
      " ['a motorcycle parked on a street next to a tree <EOS>']\n",
      " ['a woman sitting on a umbrella with a umbrella <EOS>']\n",
      " ['a pair of scissors sitting on a cutting board <EOS>']\n",
      " ['a building with a clock tower sitting on top <EOS>']]\n",
      "[['a group of zebras standing on a grass <EOS>']\n",
      " ['a living room with a white couch and table <EOS>']\n",
      " ['a train sitting on a street next to a street sign <EOS>']\n",
      " ['a bathroom with a white toilet and sink <EOS>']\n",
      " ['a man riding a surfboard on a wave <EOS>']]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(predictions)[top_idxs])\n",
    "print(np.array(predictions)[worst_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate CIDEr + Context Reward on the same images\n",
    "### ($\\beta = 0.1$, LR=1e-4)\n",
    "\n",
    "Version 2: `1 - [(gt - pred) / gt]`\n",
    "\n",
    "Up to Epoch=10, Greedy context up to 0.8536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_context = Agent(env=env)\n",
    "agent_context.actor.load_state_dict(torch.load(\n",
    "    MODEL_DIR.format('RL-0522-1313-E9'), map_location=None if USE_CUDA else 'cpu'\n",
    ")['model_state_dict'])\n",
    "# print('LOADED ACTOR WITH SCST WEIGHTS: ', SCST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0021111817846577\n"
     ]
    }
   ],
   "source": [
    "predictions = agent_context.predict_captions(img_features, mode='greedy', constrain=True)\n",
    "predictions_ = dict(zip(img_ids_, predictions))\n",
    "mean, scores = env.cider.compute_score(ground_truth, predictions_)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a group of motorcycles parked on a street top <EOS>']\n",
      " ['a traffic light with traffic lights sitting on a street top <EOS>']\n",
      " ['a group of people standing on a street with a truck bus <EOS>']\n",
      " ['a man holding a tennis racket at a ball <EOS>']\n",
      " ['a train sitting on a train station <EOS>']]\n",
      "[['a group of horses riding on a water river <EOS>']\n",
      " ['a boat with a surfboard sitting on the water <EOS>']\n",
      " ['a man flying a kite on the beach <EOS>']\n",
      " ['a bathroom with a white toilet and sink <EOS>']\n",
      " ['a group of people flying kites on a field <EOS>']]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(predictions)[top_idxs])\n",
    "print(np.array(predictions)[worst_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate CIDEr + Context Reward on the same images\n",
    "### ($\\beta = 0.1$, LR=1e-4)\n",
    "\n",
    "Version 2: `1 - [(gt - pred) / gt]`\n",
    "\n",
    "Up to Epoch=13, Greedy context up to 0.8604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_context = Agent(env=env)\n",
    "agent_context.actor.load_state_dict(torch.load(\n",
    "    MODEL_DIR.format('RL-0522-1313-E12'), map_location=None if USE_CUDA else 'cpu'\n",
    ")['model_state_dict'])\n",
    "# print('LOADED ACTOR WITH SCST WEIGHTS: ', SCST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9988473615785126\n"
     ]
    }
   ],
   "source": [
    "predictions = agent_context.predict_captions(img_features, mode='greedy', constrain=True)\n",
    "predictions_ = dict(zip(img_ids_, predictions))\n",
    "mean, scores = env.cider.compute_score(ground_truth, predictions_)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a group of motorcycles parked on a street top next to a street top <EOS>']\n",
      " ['a traffic light with traffic lights sitting on a street top <EOS>']\n",
      " ['a woman standing on a street top with a truck bus <EOS>']\n",
      " ['a man holding a tennis racket at a tennis ball <EOS>']\n",
      " ['a train sitting on a train tracks station <EOS>']]\n",
      "[['a herd of horses walking on a water river <EOS>']\n",
      " ['a boat with boats sitting on the water <EOS>']\n",
      " ['a man flying a kite on the beach <EOS>']\n",
      " ['a bathroom with a white toilet and sink <EOS>']\n",
      " ['a group of people flying kites on a field top <EOS>']]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(predictions)[top_idxs])\n",
    "print(np.array(predictions)[worst_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate CIDEr + Context Reward on the same images\n",
    "LR=1e-4\n",
    "\n",
    "Version 3: `1 - [(gt - pred) / gt]` (but gt excludes 0 values from the mean)\n",
    "CIDEr weight: 1.  Context weight: 2\n",
    "\n",
    "Up to Epoch=4,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_context = Agent(env=env)\n",
    "agent_context.actor.load_state_dict(torch.load(\n",
    "    MODEL_DIR.format('RL-0523-0900-E3'), map_location=None if USE_CUDA else 'cpu'\n",
    ")['model_state_dict'])\n",
    "# print('LOADED ACTOR WITH SCST WEIGHTS: ', SCST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = agent_context.predict_captions(img_features, mode='greedy', constrain=True)\n",
    "predictions_ = dict(zip(img_ids_, predictions))\n",
    "mean, scores = env.cider.compute_score(ground_truth, predictions_)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(predictions)[top_idxs])\n",
    "print(np.array(predictions)[worst_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "1. CIDEr-optimized captions lack complete sentence structure. For example, the word 'is' disappears from the predictions, while it is present in the base cross-entropy trained model.\n",
    "2. CIDEr-optimized captions are much shorter and convey less scene context. For example, the base model predicts `a woman is walking down a street while holding a camera <EOS>`, but the CIDEr- optimized only predicts `'a woman walking down a street with a bus <EOS>'`. This removes the detail that the woman is holding a camera, but also mistakenly says that the woman is walking with a bus. Adding a context reward to CIDEr optimization **need to add comparisons from context-reward predictions**. Another example is `'a man sitting in a chair with a dog on his lap <EOS>'` from the base model, but CIDEr-optimized simplifies this into `'a man sitting on a couch with a dog <EOS>'`, lacking detail. Four out of the five ground truth captions include the detail that the dog is on the lap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Papers [CITE] directly optimize for CIDEr, and has shown that optimizing for CIDEr also increases other commonly used metrics such as BLEU. However, the observations mentioned show that directly optimizing for CIDEr is not a good end-all be-all method to improve the quality of the captions.  (other papers may have also said this before). \n",
    "\n",
    "While the base LSTM model trained with cross-entropy incorporates more detail into its predictions, it is a rigid way of generating text. methods in which the agent is incentivized by the common metrics such as CIDEr and BLEU does not take full advantage of reinforcement learning paradigm, as it still forms a rigid learning goal. Training an agent based on context may be more beneficial in the long run, as it can learn to associate certain contexts with images, instead of relying on word order and word combinations, as is done with direct CIDEr optimization.\n",
    "\n",
    "Through this simple experiment on adding a context reward term, it may be possible to create a (middleground???). However, further experiments on the addition of the context reward term is necessary. Moreover, incorporating exploration strategies may prove to be useful, as it can take advantage of the more lenient context reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(img_ids_)[top_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(img_ids_)[worst_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
